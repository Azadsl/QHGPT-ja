import type { APIRoute } from 'astro'
import { generatePayload, parseOpenAIStream } from '@/utils/openAI'
import { verifySignature } from '@/utils/auth'
const demoKey = import.meta.env.DEMOKEY;
import prompts from "@/prompts"

const baseUrl = 'https://openrouter.ai/api';



// cloudflare pages ä¸æ”¯æŒnodeæ–¹æ³•ï¼Œç®€å•çš„ç²—ç®—
function countTokens(str: string) {
  var len = 0;
  for (var i = 0; i < str.length; i++) {
    if (str.charCodeAt(i) > 127 || str.charCodeAt(i) == 94) {
      len += 1.5;
    } else {
      len += 0.25;
    }
  }
  return Math.floor(len)
}

export const post: APIRoute = async (context) => {
  const body = await context.request.json()
  const { sign, time, messages, setting } = body
  if (!messages) {
    return new Response('No input text')
  }

  let sk = setting.openaiAPIKey || demoKey;

 
  if (sk == demoKey) {
    return new Response("ğŸ™ è¯·çœ‹ä¸‹æ–¹è¯´æ˜ï¼Œå¹¶åœ¨è®¾ç½®å¤„å¡«å…¥ API KEY")
  }

  const prompt = prompts.find((item) => item.role == setting.role)?.prompt || setting.customRule;
  let reqMessages = [];
  // ä¿ç•™messageçš„æœ€è¿‘8æ¡,ç¬¬ä¸€å¥—çš„æƒé‡æœ€ç»ˆ

  const maxToken = 4000 - countTokens(prompt) - countTokens(messages[messages.length - 1].content)

  let j = 0;
  let len = 0;
  // éå†å†å²æ¶ˆæ¯ï¼Œå¦‚æœæ¶ˆæ¯
  for (let i = messages.length - 1; i >= 0; i--) {
    const msg = messages[i];
    const lastContent = messages[i + 1] ? messages[i + 1].content : ''
    if (msg.content == lastContent) {
      continue;
    }
    len += countTokens(msg.content);
    if (i > messages.length - 6) {
      reqMessages.unshift(msg)
      continue;
    }
    j++;
    if (j > 10 || len > maxToken) {
      break;
    }
    reqMessages.unshift(msg)
  }
  // ç¡®ä¿ç¬¬ä¸€æ¡æŒ‡ä»¤æ˜¯ç©å®¶çš„å¤æ‚æŒ‡ä»¤
  const fm = messages[0]
  if (fm.role == "user" && reqMessages[0].content != fm.content && fm.content.length > 20) {
    reqMessages.unshift(fm)
  }
  if (prompt) {
    reqMessages.unshift({
      role: "system",
      content: prompt,
    })
  }

  const initOptions = generatePayload(sk, 0.8, reqMessages);
  // @ts-ignore
  let response = new Response();

  try {
    response = await fetch(`${baseUrl}/v1/chat/completions`, initOptions) as Response;
    if (response.status > 400) {
      throw new Error(`${response.status}:${response.statusText}`);
    }
  } catch (error) {
    return new Response(`âš ï¸OpenAi server response error ${error}`)
  }

  return new Response(parseOpenAIStream(response))
}



export const get: APIRoute = async (context) => {
  const roles = prompts.filter((item) => {
    return !!item.enabled
  }).map((item) => {
    return {
      ...item,
      "prompt": ''
    }
  })
  return new Response(JSON.stringify(roles), {
    headers: {
      'Content-Type': 'application/json',
    }
  })
}
